# PLAN MAESTRO - PROYECTO FINAL MACHINE LEARNING
## Marketing Campaign Response Prediction

---

## üìã INFORMACI√ìN GENERAL DEL PROYECTO

### Contexto del Negocio
**Objetivo Principal**: Predecir qui√©n responder√° a una oferta de producto/servicio en una campa√±a de marketing para maximizar la eficiencia y rentabilidad de futuras campa√±as.

**Dataset**: Marketing Campaign (marketing_campaign.csv)
- **Variable Objetivo**: `Response` (1 si acept√≥ la oferta en la √∫ltima campa√±a, 0 si no)
- **Tipo de Problema**: Clasificaci√≥n Binaria Supervisada
- **Aplicaci√≥n**: Modelo de respuesta para optimizar campa√±as de marketing

### Estructura de Entregas
- **Punto 1**: 29.10.2025 - Estructura y EDA
- **Entrega Final**: 10.11.2025 23:59
- **Repositorio**: GitHub p√∫blico compartido con `juanseparracourses`
- **Ramas requeridas**: `developer`, `certification`, `master`

---

## üìä VARIABLES DEL DATASET

### Variables de Campa√±as Anteriores
- `AcceptedCmp1` a `AcceptedCmp5`: Aceptaci√≥n en campa√±as 1-5 (binarias)
- `Response`: **VARIABLE OBJETIVO** - Aceptaci√≥n en √∫ltima campa√±a (binaria)
- `Complain`: Quejas en √∫ltimos 2 a√±os (binaria)

### Variables Demogr√°ficas
- `DtCustomer`: Fecha de inscripci√≥n del cliente
- `Education`: Nivel educativo
- `Marital`: Estado civil
- `Kidhome`: N√∫mero de ni√±os peque√±os en el hogar
- `Teenhome`: N√∫mero de adolescentes en el hogar
- `Income`: Ingreso anual del hogar

### Variables de Comportamiento de Compra (√öltimos 2 a√±os)
- `MntFishProducts`: Gasto en pescado
- `MntMeatProducts`: Gasto en carne
- `MntFruits`: Gasto en frutas
- `MntSweetProducts`: Gasto en dulces
- `MntWines`: Gasto en vinos
- `MntGoldProds`: Gasto en productos gold

### Variables de Canales de Compra
- `NumDealsPurchases`: Compras con descuento
- `NumCatalogPurchases`: Compras por cat√°logo
- `NumStorePurchases`: Compras en tienda f√≠sica
- `NumWebPurchases`: Compras por web
- `NumWebVisitsMonth`: Visitas al sitio web (√∫ltimo mes)
- `Recency`: D√≠as desde √∫ltima compra

---

## üèóÔ∏è ESTRUCTURA DEL REPOSITORIO (OBLIGATORIA)

```
final-project-ml_Alejo/
‚îú‚îÄ‚îÄ mlops_pipeline/
‚îÇ   ‚îî‚îÄ‚îÄ src/
‚îÇ       ‚îú‚îÄ‚îÄ Cargar_datos.ipynb          [COMPLETADO]
‚îÇ       ‚îú‚îÄ‚îÄ comprension_eda.ipynb       [PENDIENTE]
‚îÇ       ‚îú‚îÄ‚îÄ ft_engineering.py           [ESQUELETO CREADO]
‚îÇ       ‚îú‚îÄ‚îÄ model_training_evaluation.py [PENDIENTE]
‚îÇ       ‚îú‚îÄ‚îÄ model_deploy.py             [PENDIENTE]
‚îÇ       ‚îî‚îÄ‚îÄ model_monitoring.py         [PENDIENTE]
‚îú‚îÄ‚îÄ Base_de_datos.csv                   [PENDIENTE - Copiar marketing_campaign.csv]
‚îú‚îÄ‚îÄ requirements.txt                    [B√ÅSICO - NECESITA ACTUALIZACI√ìN]
‚îú‚îÄ‚îÄ .gitignore                          [COMPLETADO]
‚îú‚îÄ‚îÄ setup.bat                           [COMPLETADO]
‚îî‚îÄ‚îÄ README.md                           [B√ÅSICO - NECESITA DESARROLLO]
```

---

## üéØ FASES DE IMPLEMENTACI√ìN DEL PROYECTO

---

### **FASE 0: PREPARACI√ìN INICIAL** ‚úÖ
**Estado**: COMPLETADO
**Responsable**: Manual + Asistente

#### Tareas:
- [x] Crear repositorio en GitHub
- [x] Configurar estructura de carpetas
- [x] Crear archivo requirements.txt b√°sico
- [x] Configurar .gitignore
- [x] Crear setup.bat para entorno virtual
- [ ] **MANUAL**: Copiar marketing_campaign.csv a Base_de_datos.csv
- [ ] **MANUAL**: Crear ramas developer, certification, master
- [ ] **MANUAL**: Compartir repo con juanseparracourses

#### Entregables:
- Repositorio con estructura correcta
- Entorno virtual configurado

---

### **FASE 1: EXPLORACI√ìN Y AN√ÅLISIS DE DATOS (EDA)**
**Archivo**: `mlops_pipeline/src/comprension_eda.ipynb`
**Peso en Evaluaci√≥n**: 0.7 puntos
**Estado**: PENDIENTE

#### 1.1 Exploraci√≥n Inicial de Datos
**Checklist de Evaluaci√≥n**:
- [ ] Descripci√≥n general del dataset
- [ ] Caracterizaci√≥n de variables (categ√≥ricas, num√©ricas, ordinales, nominales, dicot√≥micas, polit√≥micas)
- [ ] Revisi√≥n de valores nulos
- [ ] Unificaci√≥n de representaci√≥n de nulos
- [ ] Eliminaci√≥n de variables irrelevantes
- [ ] Conversi√≥n de datos a tipos correctos (num√©ricos, categ√≥ricos, booleanos, fechas)
- [ ] Correcci√≥n de inconsistencias

**An√°lisis Espec√≠fico para Marketing Campaign**:
- Identificar tipos de variables:
  - **Binarias**: AcceptedCmp1-5, Response, Complain
  - **Num√©ricas continuas**: Income, Mnt* (gastos), Recency
  - **Num√©ricas discretas**: Kidhome, Teenhome, Num* (conteos)
  - **Categ√≥ricas**: Education, Marital
  - **Fecha**: DtCustomer
- Detectar nulos especialmente en Income (com√∫n en datasets de marketing)
- Validar rangos l√≥gicos (Income > 0, Recency >= 0, etc.)

#### 1.2 An√°lisis Univariable
**Checklist de Evaluaci√≥n**:
- [ ] Ejecutar describe() despu√©s de ajustar tipos
- [ ] Histogramas y boxplots para variables num√©ricas
- [ ] Countplot, value_counts() y tablas pivote para categ√≥ricas
- [ ] Medidas estad√≠sticas: media, mediana, moda, max, min
- [ ] Medidas de dispersi√≥n: rango, IQR, cuartiles, varianza, desviaci√≥n est√°ndar
- [ ] Skewness y kurtosis
- [ ] Identificar tipo de distribuci√≥n

**An√°lisis Espec√≠fico**:
- **Variable Objetivo (Response)**: Verificar balance de clases
- **Gastos (Mnt*)**: Analizar distribuci√≥n (probablemente sesgada)
- **Income**: Detectar outliers y distribuci√≥n
- **Recency**: Patr√≥n de recencia de compras
- **Campa√±as anteriores**: Tasa de aceptaci√≥n hist√≥rica

#### 1.3 An√°lisis Bivariable
**Checklist de Evaluaci√≥n**:
- [ ] Gr√°ficos y tablas con respecto a variable objetivo (Response)
- [ ] Comentarios e interpretaciones

**An√°lisis Espec√≠fico**:
- Response vs AcceptedCmp1-5 (correlaci√≥n entre campa√±as)
- Response vs Income (poder adquisitivo)
- Response vs gastos totales (engagement)
- Response vs Education/Marital (demograf√≠a)
- Response vs canales de compra (preferencias)
- Response vs Recency (actividad reciente)

#### 1.4 An√°lisis Multivariable
**Checklist de Evaluaci√≥n**:
- [ ] Pairplot de variables clave
- [ ] Matriz de correlaci√≥n
- [ ] Gr√°ficos de dispersi√≥n entre num√©ricas
- [ ] Uso de par√°metro hue para categ√≥ricas
- [ ] Identificar reglas de validaci√≥n de datos
- [ ] Identificar transformaciones aplicables
- [ ] Sugerir atributos derivados/calculados

**An√°lisis Espec√≠fico**:
- Correlaci√≥n entre AcceptedCmp1-5 y Response
- Correlaci√≥n entre diferentes tipos de gastos
- Relaci√≥n Income vs gastos totales
- Segmentaci√≥n por Education + Marital + Response
- Interacci√≥n Kidhome + Teenhome vs patrones de compra

**Atributos Derivados Sugeridos**:
- `TotalSpent`: Suma de todos los Mnt*
- `TotalPurchases`: Suma de todos los Num*Purchases
- `TotalAcceptedCampaigns`: Suma de AcceptedCmp1-5
- `HasChildren`: Kidhome + Teenhome > 0
- `CustomerAge`: D√≠as desde DtCustomer
- `AvgPurchaseValue`: TotalSpent / TotalPurchases
- `WebEngagement`: NumWebPurchases / NumWebVisitsMonth

#### Entregables Fase 1:
- Notebook comprension_eda.ipynb completamente documentado
- Insights clave sobre el comportamiento de clientes
- Lista de transformaciones necesarias
- Propuesta de features derivados

---

### **FASE 2: INGENIER√çA DE CARACTER√çSTICAS**
**Archivo**: `mlops_pipeline/src/ft_engineering.py`
**Peso en Evaluaci√≥n**: 0.5 puntos
**Estado**: ESQUELETO CREADO

#### 2.1 Desarrollo del Pipeline de Features
**Checklist de Evaluaci√≥n**:
- [ ] Genera correctamente features desde dataset base
- [ ] Flujo de transformaci√≥n documentado
- [ ] Pipelines de sklearn creados
- [ ] Separaci√≥n correcta train/test
- [ ] Retorna dataset limpio para modelado
- [ ] Transformaciones: escalado, codificaci√≥n, imputaci√≥n
- [ ] Decisiones documentadas

**Componentes del Pipeline**:

1. **Limpieza de Datos**:
   - Manejo de nulos en Income (imputaci√≥n por mediana o eliminaci√≥n)
   - Unificaci√≥n de categor√≠as en Education/Marital
   - Eliminaci√≥n de outliers extremos

2. **Feature Engineering**:
   - Crear features derivados (TotalSpent, TotalPurchases, etc.)
   - Extraer features de DtCustomer (antig√ºedad, mes/a√±o registro)
   - Binning de variables continuas si necesario
   - Interacciones relevantes

3. **Transformaciones**:
   - **Num√©ricas**: StandardScaler o RobustScaler (por outliers)
   - **Categ√≥ricas**: OneHotEncoder o LabelEncoder
   - **Fechas**: Convertir a features num√©ricas

4. **Pipeline de sklearn**:
   ```python
   from sklearn.pipeline import Pipeline
   from sklearn.compose import ColumnTransformer
   from sklearn.preprocessing import StandardScaler, OneHotEncoder
   from sklearn.impute import SimpleImputer
   ```

5. **Split de Datos**:
   - train_test_split con test_size=0.2, random_state=42
   - Estratificaci√≥n por Response (por desbalance de clases)

#### Entregables Fase 2:
- ft_engineering.py con funciones completas
- Pipelines de transformaci√≥n reutilizables
- X_train, X_test, y_train, y_test guardados
- Documentaci√≥n de decisiones

---

### **FASE 3: ENTRENAMIENTO Y EVALUACI√ìN DE MODELOS**
**Archivo**: `mlops_pipeline/src/model_training_evaluation.py`
**Peso en Evaluaci√≥n**: 1.0 punto
**Estado**: PENDIENTE

#### 3.1 Desarrollo de Funciones Reutilizables
**Checklist de Evaluaci√≥n**:
- [ ] Funci√≥n build_model() para entrenamiento estructurado
- [ ] Funci√≥n summarize_classification() para m√©tricas

**Funciones Requeridas**:
```python
def build_model(model, X_train, y_train, X_test, y_test):
    """Entrena y eval√∫a un modelo"""
    # Entrenamiento
    # Predicci√≥n
    # M√©tricas
    # Retornar resultados
    
def summarize_classification(y_true, y_pred, model_name):
    """Resume m√©tricas de clasificaci√≥n"""
    # Accuracy, Precision, Recall, F1-Score
    # Matriz de confusi√≥n
    # ROC-AUC
    # Retornar dict de m√©tricas
```

#### 3.2 Entrenamiento de Modelos
**Checklist de Evaluaci√≥n**:
- [ ] M√∫ltiples modelos supervisados entrenados
- [ ] Validaci√≥n cruzada aplicada
- [ ] Modelo seleccionado guardado

**Modelos a Entrenar** (m√≠nimo 5):
1. **Logistic Regression** (baseline)
2. **Random Forest Classifier**
3. **XGBoost Classifier**
4. **LightGBM Classifier**
5. **Support Vector Machine (SVM)**
6. **Gradient Boosting Classifier**
7. **Extra Trees Classifier** (opcional)

**T√©cnicas de Validaci√≥n**:
- Cross-validation (5-fold o 10-fold)
- Stratified K-Fold (por desbalance)
- GridSearchCV o RandomizedSearchCV para hiperpar√°metros

#### 3.3 Evaluaci√≥n y Comparaci√≥n
**Checklist de Evaluaci√≥n**:
- [ ] M√©tricas: accuracy, precision, recall, F1-score, ROC-AUC
- [ ] Gr√°ficos comparativos (curvas ROC, matriz confusi√≥n)
- [ ] Justificaci√≥n de selecci√≥n del mejor modelo

**M√©tricas Clave para Marketing**:
- **Recall**: Capturar m√°ximo de clientes que responder√°n
- **Precision**: Evitar gastar en clientes que no responder√°n
- **F1-Score**: Balance entre ambos
- **ROC-AUC**: Capacidad de discriminaci√≥n
- **Profit Curve**: Maximizar beneficio de campa√±a

**Visualizaciones Requeridas**:
- Tabla comparativa de todos los modelos
- Curvas ROC superpuestas
- Matrices de confusi√≥n
- Feature importance del mejor modelo
- Gr√°fico de barras con m√©tricas comparativas

#### 3.4 Selecci√≥n del Modelo Final
**Criterios**:
- **Performance**: Mejores m√©tricas en test set
- **Consistency**: Bajo overfitting (train vs test)
- **Scalability**: Tiempo de entrenamiento/predicci√≥n
- **Interpretability**: Importancia para negocio

**Guardar Modelo**:
```python
import joblib
joblib.dump(best_model, 'best_model.pkl')
```

#### Entregables Fase 3:
- model_training_evaluation.py completo
- Modelo final guardado (.pkl o .joblib)
- Reporte comparativo de modelos
- Justificaci√≥n t√©cnica de selecci√≥n

---

### **FASE 4: MONITOREO Y DETECCI√ìN DE DATA DRIFT**
**Archivo**: `mlops_pipeline/src/model_monitoring.py`
**Peso en Evaluaci√≥n**: 1.0 punto
**Estado**: PENDIENTE

#### 4.1 Implementaci√≥n de M√©tricas de Drift
**Checklist de Evaluaci√≥n**:
- [ ] Test de Drift calculado (KS, PSI, JS, Chi-cuadrado)

**M√©tricas a Implementar**:

1. **Kolmogorov-Smirnov Test** (variables num√©ricas):
   ```python
   from scipy.stats import ks_2samp
   ```

2. **Population Stability Index (PSI)**:
   - PSI < 0.1: Sin cambio significativo
   - 0.1 ‚â§ PSI < 0.2: Cambio moderado
   - PSI ‚â• 0.2: Cambio significativo

3. **Jensen-Shannon Divergence**:
   ```python
   from scipy.spatial.distance import jensenshannon
   ```

4. **Chi-cuadrado** (variables categ√≥ricas):
   ```python
   from scipy.stats import chi2_contingency
   ```

**Implementaci√≥n**:
- Muestreo peri√≥dico de datos
- Comparaci√≥n distribuci√≥n hist√≥rica vs actual
- C√°lculo de m√©tricas por variable
- Generaci√≥n de alertas por umbrales

#### 4.2 Aplicaci√≥n en Streamlit
**Checklist de Evaluaci√≥n**:
- [ ] Interfaz funcional en Streamlit
- [ ] Gr√°ficos comparativos distribuci√≥n hist√≥rica vs actual
- [ ] Indicadores visuales de alerta (sem√°foro, barras)
- [ ] Alertas por desviaciones significativas

**Componentes de la App**:

1. **Dashboard Principal**:
   - Resumen de estado de drift
   - Sem√°foros por variable (verde/amarillo/rojo)
   - √öltima actualizaci√≥n

2. **Visualizaci√≥n de M√©tricas**:
   - Tabla con m√©tricas de drift por variable
   - Gr√°ficos de distribuci√≥n hist√≥rica vs actual
   - Histogramas superpuestos
   - Box plots comparativos

3. **An√°lisis Temporal**:
   - Evoluci√≥n del drift en el tiempo
   - Detecci√≥n de tendencias
   - Cambios abruptos

4. **Recomendaciones**:
   - Mensajes autom√°ticos si umbral cr√≠tico
   - Sugerencias de retraining
   - Variables a revisar

**Estructura de la App**:
```python
import streamlit as st
import pandas as pd
import plotly.express as px

st.title("üîç Monitoreo de Data Drift - Marketing Campaign")

# Sidebar con configuraci√≥n
# Secci√≥n de m√©tricas generales
# Secci√≥n de an√°lisis por variable
# Secci√≥n de alertas y recomendaciones
```

#### Entregables Fase 4:
- model_monitoring.py con funciones de drift
- Aplicaci√≥n Streamlit funcional
- Documentaci√≥n de umbrales y alertas

---

### **FASE 5: DESPLIEGUE DEL MODELO**
**Archivo**: `mlops_pipeline/src/model_deploy.py`
**Peso en Evaluaci√≥n**: 1.0 punto
**Estado**: PENDIENTE

#### 5.1 Desarrollo de API con FastAPI
**Checklist de Evaluaci√≥n**:
- [ ] Framework adecuado (FastAPI o Flask)
- [ ] Endpoint /predict definido
- [ ] Acepta JSON y/o CSV
- [ ] Soporta predicci√≥n por lotes
- [ ] Retorna predicci√≥n en formato estructurado

**Estructura de la API**:

```python
from fastapi import FastAPI, File, UploadFile
from pydantic import BaseModel
import joblib
import pandas as pd

app = FastAPI(title="Marketing Campaign Prediction API")

# Cargar modelo
model = joblib.load('best_model.pkl')

# Modelo de datos
class CustomerData(BaseModel):
    Income: float
    Recency: int
    # ... todas las features
    
# Endpoint de predicci√≥n individual
@app.post("/predict")
def predict_single(data: CustomerData):
    # Transformar a DataFrame
    # Aplicar pipeline
    # Predecir
    # Retornar resultado
    
# Endpoint de predicci√≥n por lotes
@app.post("/predict_batch")
def predict_batch(file: UploadFile):
    # Leer CSV
    # Predecir
    # Retornar resultados
    
# Endpoint de salud
@app.get("/health")
def health_check():
    return {"status": "healthy"}
```

**Endpoints Requeridos**:
- `GET /`: Informaci√≥n de la API
- `GET /health`: Health check
- `POST /predict`: Predicci√≥n individual (JSON)
- `POST /predict_batch`: Predicci√≥n por lotes (CSV/JSON)

#### 5.2 Dockerizaci√≥n
**Checklist de Evaluaci√≥n**:
- [ ] Dockerfile funcional con instrucciones claras

**Dockerfile**:
```dockerfile
FROM python:3.9-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY mlops_pipeline/src/ ./src/
COPY best_model.pkl .

EXPOSE 8000

CMD ["uvicorn", "src.model_deploy:app", "--host", "0.0.0.0", "--port", "8000"]
```

**Archivos Necesarios**:
- `Dockerfile`
- `.dockerignore`
- `docker-compose.yml` (opcional)

**Comandos Docker**:
```bash
# Build
docker build -t marketing-campaign-api .

# Run
docker run -p 8000:8000 marketing-campaign-api

# Test
curl http://localhost:8000/health
```

#### Entregables Fase 5:
- model_deploy.py con API completa
- Dockerfile funcional
- Documentaci√≥n de endpoints
- Ejemplos de uso de la API

---

### **FASE 6: INTEGRACI√ìN CON SONARCLOUD**
**Peso en Evaluaci√≥n**: 0.5 puntos
**Estado**: PENDIENTE
**Responsable**: MANUAL

#### 6.1 Configuraci√≥n de SonarCloud
**Checklist de Evaluaci√≥n**:
- [ ] Repositorio vinculado a SonarCloud
- [ ] Configuraci√≥n creada y pruebas generadas

**Pasos Manuales**:
1. Ir a https://sonarcloud.io
2. Registrarse con cuenta de GitHub
3. Importar repositorio final-project-ml_Alejo
4. Configurar an√°lisis autom√°tico
5. Crear archivo `sonar-project.properties`

**Archivo sonar-project.properties**:
```properties
sonar.projectKey=tu-usuario_final-project-ml_Alejo
sonar.organization=tu-organizacion

sonar.sources=mlops_pipeline/src
sonar.python.version=3.9

sonar.exclusions=**/*.ipynb,**/__pycache__/**,**/venv/**
```

#### 6.2 Validaciones de SonarCloud

**1. Calidad del C√≥digo**:
- C√≥digo duplicado
- Complejidad ciclom√°tica
- Funciones largas
- Malas pr√°cticas

**2. Seguridad**:
- Exposici√≥n de datos sensibles
- Uso inseguro de librer√≠as

**3. Cobertura de Pruebas**:
- L√≠neas ejecutadas en tests
- M√©todos validados

**4. Integridad y Estilo**:
- Nombres de variables/funciones
- Indentaci√≥n y espacios
- Consistencia

**Acciones Correctivas**:
- Refactorizar c√≥digo duplicado
- Simplificar funciones complejas
- Agregar docstrings
- Seguir PEP 8

#### Entregables Fase 6:
- Badge de SonarCloud en README
- Reporte de calidad del c√≥digo
- Capturas de pantalla de an√°lisis

---

### **FASE 7: DOCUMENTACI√ìN FINAL**
**Archivo**: `README.md`
**Estado**: B√ÅSICO - NECESITA DESARROLLO

#### 7.1 Contenido del README

**Estructura Requerida**:

```markdown
# Marketing Campaign Response Prediction

## üìä Contexto del Negocio
[Descripci√≥n del problema y objetivo]

## üéØ Objetivo del Proyecto
[Objetivo espec√≠fico del modelo]

## üìÅ Estructura del Proyecto
[√Årbol de carpetas con descripci√≥n]

## üìà Dataset
[Descripci√≥n de variables y fuente]

## üîç Principales Hallazgos del EDA
[Insights clave del an√°lisis exploratorio]

## üõ†Ô∏è Proceso de Desarrollo

### 1. Exploraci√≥n de Datos
[Resumen de EDA]

### 2. Ingenier√≠a de Caracter√≠sticas
[Features creados y transformaciones]

### 3. Entrenamiento de Modelos
[Modelos probados y resultados]

### 4. Modelo Seleccionado
[Justificaci√≥n y m√©tricas]

### 5. Monitoreo
[Estrategia de drift detection]

### 6. Despliegue
[API y Docker]

## üöÄ Instalaci√≥n y Uso

### Requisitos Previos
[Python version, etc.]

### Instalaci√≥n
```bash
git clone [repo]
cd final-project-ml_Alejo
setup.bat
```

### Ejecuci√≥n
[Comandos para correr notebooks, API, Streamlit]

## üìä Resultados
[Tabla con m√©tricas finales]

## üîß Tecnolog√≠as Utilizadas
[Lista de librer√≠as y herramientas]

## üë• Autor
[Tu nombre]

## üìÑ Licencia
[Si aplica]

## üèÜ SonarCloud
[Badge de calidad]
```

#### Entregables Fase 7:
- README.md completo y profesional
- Documentaci√≥n clara y concisa
- Badges de calidad y estado

---

## üìã CHECKLIST COMPLETO DE EVALUACI√ìN

### Estructura y Configuraciones (0.3 puntos)
- [ ] Estructura m√≠nima respetada
- [ ] requirements.txt con dependencias
- [ ] Entorno virtual configurado y documentado

### An√°lisis de Datos (0.7 puntos)
- [ ] Descripci√≥n general del dataset
- [ ] Tipos de variables identificados
- [ ] Valores nulos revisados y unificados
- [ ] Variables irrelevantes eliminadas
- [ ] Datos convertidos a tipos correctos
- [ ] describe() ejecutado
- [ ] Histogramas y boxplots para num√©ricas
- [ ] Countplot y value_counts para categ√≥ricas
- [ ] Medidas estad√≠sticas completas
- [ ] Tipo de distribuci√≥n identificado
- [ ] An√°lisis bivariable con variable objetivo
- [ ] An√°lisis multivariable (pairplot, correlaci√≥n)
- [ ] Reglas de validaci√≥n identificadas
- [ ] Atributos derivados sugeridos

### Ingenier√≠a de Caracter√≠sticas (0.5 puntos)
- [ ] Features generados correctamente
- [ ] Flujo documentado
- [ ] Pipelines de sklearn creados
- [ ] Train/test separados correctamente
- [ ] Dataset limpio retornado
- [ ] Transformaciones aplicadas
- [ ] Decisiones documentadas

### Entrenamiento y Evaluaci√≥n (1.0 punto)
- [ ] M√∫ltiples modelos entrenados
- [ ] Funci√≥n build_model() implementada
- [ ] Validaci√≥n cruzada aplicada
- [ ] Modelo guardado
- [ ] Funci√≥n summarize_classification() implementada
- [ ] M√©tricas completas calculadas
- [ ] Gr√°ficos comparativos generados
- [ ] Selecci√≥n justificada

### Monitoreo (1.0 punto)
- [ ] Test de drift calculado
- [ ] Interfaz Streamlit funcional
- [ ] Gr√°ficos comparativos de distribuci√≥n
- [ ] Indicadores visuales de alerta
- [ ] Alertas por desviaciones

### Despliegue (1.0 punto)
- [ ] Framework adecuado usado
- [ ] Endpoint /predict definido
- [ ] JSON y/o CSV aceptado
- [ ] Predicci√≥n por lotes soportada
- [ ] Formato estructurado retornado
- [ ] Dockerfile funcional

### SonarCloud (0.5 puntos)
- [ ] Repositorio vinculado
- [ ] Configuraci√≥n y pruebas generadas

**TOTAL: 5.0 puntos**

---

## üîß DEPENDENCIAS ACTUALIZADAS

### requirements.txt Completo
```
# Data manipulation
pandas==1.5.3
numpy==1.24.3

# Machine Learning
scikit-learn==1.2.2
xgboost==1.7.5
lightgbm==3.3.5

# Visualization
matplotlib==3.7.1
seaborn==0.12.2
plotly==5.14.1

# Notebooks
jupyter==1.0.0
ipykernel==6.22.0

# API
fastapi==0.95.1
uvicorn==0.22.0
pydantic==1.10.7
python-multipart==0.0.6

# Streamlit
streamlit==1.22.0

# Data Drift
scipy==1.10.1

# Model persistence
joblib==1.2.0

# Utilities
python-dotenv==1.0.0
```

---

## üìù TAREAS MANUALES REQUERIDAS

### Antes de Empezar:
1. ‚úÖ **Copiar dataset**: `marketing_campaign.csv` ‚Üí `Base_de_datos.csv`
2. ‚úÖ **Crear ramas en GitHub**:
   ```bash
   git checkout -b developer
   git push origin developer
   git checkout -b certification
   git push origin certification
   git checkout main
   ```
3. ‚úÖ **Compartir repositorio**: Agregar a `juanseparracourses` como colaborador

### Durante el Desarrollo:
4. ‚ö†Ô∏è **Ejecutar notebooks**: Los .ipynb deben ejecutarse manualmente
5. ‚ö†Ô∏è **Revisar visualizaciones**: Validar que gr√°ficos sean correctos
6. ‚ö†Ô∏è **Probar API**: Testear endpoints con Postman o curl
7. ‚ö†Ô∏è **Ejecutar Streamlit**: Validar interfaz de monitoreo

### Al Final:
8. ‚ö†Ô∏è **Configurar SonarCloud**: Registro y vinculaci√≥n manual
9. ‚ö†Ô∏è **Revisar calidad de c√≥digo**: Corregir issues de SonarCloud
10. ‚ö†Ô∏è **Hacer commits**: Usar mensajes descriptivos
11. ‚ö†Ô∏è **Merge a master**: Desde developer ‚Üí certification ‚Üí master
12. ‚ö†Ô∏è **Verificar entrega**: Revisar checklist completo

---

## üéØ ESTRATEGIA DE TRABAJO

### Orden Recomendado de Ejecuci√≥n:
1. **Fase 1**: EDA completo (2-3 d√≠as)
2. **Fase 2**: Feature Engineering (1 d√≠a)
3. **Fase 3**: Entrenamiento de modelos (2 d√≠as)
4. **Fase 4**: Monitoreo (1 d√≠a)
5. **Fase 5**: Despliegue (1 d√≠a)
6. **Fase 6**: SonarCloud (0.5 d√≠a)
7. **Fase 7**: Documentaci√≥n (0.5 d√≠a)

### Uso de este Documento:
- **Cuando se llene el contexto**: Referencia este archivo
- **Para retomar trabajo**: Indica "Estoy en Fase X, secci√≥n Y"
- **Para validar progreso**: Marca checkboxes completados
- **Para consultar requisitos**: Busca en checklist de evaluaci√≥n

---

## üìû CONTACTO Y SOPORTE

**Docente**: Juan Sebasti√°n Parra S√°nchez
**Usuario GitHub**: juanseparracourses
**Fecha l√≠mite**: 10 de noviembre de 2025, 23:59

---

**√öltima actualizaci√≥n**: 11 de noviembre de 2025
**Versi√≥n**: 1.0
**Estado del Proyecto**: FASE 0 COMPLETADA - INICIANDO FASE 1

